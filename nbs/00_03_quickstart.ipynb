{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd51a173-a03f-4ca8-8cf6-95ab8cfc8503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    /* Font imports */\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&family=Source+Code+Pro:ital,wght@0,200..900;1,200..900&display=swap');\n",
       "\n",
       "    /* Variables */\n",
       "    :root {\n",
       "        --primary-color: #05bfa5;\n",
       "        --primary-light: #FAFAFA;\n",
       "        --text-color: #2c3e50;\n",
       "        --code-bg: #f8f8f8;\n",
       "        --code-fg: #b22222;\n",
       "        --success-color: #479269;\n",
       "        --warning-color: #f39c12;\n",
       "        --danger-color: #e74c3c;\n",
       "        --border-radius: 8px;\n",
       "        --spacing-sm: 0.3em;\n",
       "        --spacing-md: 1em;\n",
       "        --spacing-lg: 2em;\n",
       "    }\n",
       "\n",
       "    /* Container styles */\n",
       "    .h1-container, .h2-container, .h3-container {\n",
       "        font-family: 'Montserrat', sans-serif;\n",
       "        max-width: 95%;\n",
       "        margin: var(--spacing-lg) auto;\n",
       "        line-height: 1.6;\n",
       "        color: var(--text-color);\n",
       "    }\n",
       "\n",
       "    /* List styles */\n",
       "    .feature-list {\n",
       "        background-color: var(--primary-light);\n",
       "        padding: var(--spacing-sm) var(--spacing-lg);\n",
       "        border-radius: var(--border-radius);\n",
       "        border-left: 4px solid var(--primary-color);\n",
       "        margin: var(--spacing-md) 0;\n",
       "    }\n",
       "\n",
       "    /* Code styles */\n",
       "    .code-mention {\n",
       "        font-family: 'Source Code Pro', monospace !important;\n",
       "        background-color: var(--code-bg) !important;\n",
       "        padding: 2px 5px;\n",
       "        font-weight: 600 !important;\n",
       "        border-radius: 4px;\n",
       "        color: var(--code-fg) !important;\n",
       "    }\n",
       "\n",
       "    .code-block {\n",
       "        background-color: var(--primary-light);\n",
       "        border-left: 4px solid var(--primary-color);\n",
       "        padding: var(--spacing-md);\n",
       "        margin: var(--spacing-md) 0;\n",
       "        border-radius: var(--border-radius);\n",
       "        padding: var(--spacing-lg);\n",
       "        max-width: 90%;\n",
       "    }\n",
       "\n",
       "    /* Information blocks */\n",
       "    .note-block, .notice-block {\n",
       "        padding: var(--spacing-md);\n",
       "        border-radius: var(--border-radius);\n",
       "        margin: var(--spacing-md) 0;\n",
       "    }\n",
       "\n",
       "    .note-block {\n",
       "        background-color: var(--primary-light);\n",
       "        border-left: 4px solid var(--success-color);\n",
       "    }\n",
       "\n",
       "    .notice-block {\n",
       "        background-color: var(--primary-light);\n",
       "        border-left: 4px solid var(--warning-color);\n",
       "    }\n",
       "\n",
       "    .note-title {\n",
       "        margin-top: 0;\n",
       "        color: var(--success-color);\n",
       "        font-weight: 600;\n",
       "    }\n",
       "\n",
       "    .feature-list:hover {\n",
       "        background-color: #f0f0f0;\n",
       "    }\n",
       "    .code-block:hover {\n",
       "        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
       "    }\n",
       "\n",
       "    /* Utility styles */\n",
       "    .code-comment {\n",
       "        color: #607d8b;\n",
       "        font-style: italic;\n",
       "    }\n",
       "\n",
       "    .highlight {\n",
       "        background-color: #fff176;\n",
       "        padding: 2px 5px;\n",
       "        border-radius: 3px;\n",
       "    }\n",
       "    </style>\n",
       "    <style>\n",
       "<style>\n",
       "/* General styles */\n",
       ".result-container {\n",
       "    max-width: 90%;\n",
       "    margin: 1em 0;\n",
       "}\n",
       "\n",
       "/* Card Styling */\n",
       ".result-card {\n",
       "    background-color: #f8f9fa;\n",
       "    border-left: 4px solid #05bfa5;\n",
       "    border-radius: 8px;\n",
       "    margin-bottom: 1em;\n",
       "    overflow: hidden;\n",
       "}\n",
       "\n",
       "/* Header Styling */\n",
       ".result-header {\n",
       "    display: flex;\n",
       "    justify-content: space-between;\n",
       "    align-items: center;\n",
       "    padding: 0.8em 1em;\n",
       "    font-family: 'Source Code Pro', monospace;\n",
       "    font-weight: bold;\n",
       "    font-size: 1.05em;\n",
       "    color: #2c3e50;\n",
       "    background-color: #e9ecef;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".result-header:hover {\n",
       "    background-color: #dfe4ea;\n",
       "}\n",
       "\n",
       "/* Content Styling */\n",
       ".result-content {\n",
       "    display: none;\n",
       "    padding: 0.8em 1em;\n",
       "    font-family: 'Source Code Pro', monospace;\n",
       "    font-size: 0.95em;\n",
       "    color: #34495e;\n",
       "}\n",
       "\n",
       "/* Link Styling */\n",
       ".result-link {\n",
       "    text-decoration: none;\n",
       "    color: #3498db;\n",
       "    font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "// JavaScript function to toggle visibility of the result content and icon\n",
       "function toggleContent(id, iconId) {\n",
       "    var content = document.getElementById(id);\n",
       "    var icon = document.getElementById(iconId);\n",
       "    if (content.style.display === \"none\" || content.style.display === \"\") {\n",
       "        content.style.display = \"block\";\n",
       "        icon.innerHTML = \"&#9660;\";  // Change to down-facing arrow\n",
       "    } else {\n",
       "        content.style.display = \"none\";\n",
       "        icon.innerHTML = \"&#9654;\";  // Change to right-facing arrow\n",
       "    }\n",
       "}\n",
       "</script>\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m\n",
      "✅ Environment Variables Loaded Successfully\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Project library Imports\n",
    "from lc_tutorials.appearance.notebook import apply_custom_styles, cprint\n",
    "from lc_tutorials.appearance.displays import display_tavily_search_results\n",
    "from lc_tutorials.functionality.utils import setup_environment\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import display, HTML, Markdown, Image, Javascript\n",
    "\n",
    "# Third-party imports\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from colorama import Back, Fore, Style, init\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# LangGraph Imports\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# LangChain Imports\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "custom_style=\"\"\"\n",
    "<style>\n",
    "/* General styles */\n",
    ".result-container {\n",
    "    max-width: 90%;\n",
    "    margin: 1em 0;\n",
    "}\n",
    "\n",
    "/* Card Styling */\n",
    ".result-card {\n",
    "    background-color: #f8f9fa;\n",
    "    border-left: 4px solid #05bfa5;\n",
    "    border-radius: 8px;\n",
    "    margin-bottom: 1em;\n",
    "    overflow: hidden;\n",
    "}\n",
    "\n",
    "/* Header Styling */\n",
    ".result-header {\n",
    "    display: flex;\n",
    "    justify-content: space-between;\n",
    "    align-items: center;\n",
    "    padding: 0.8em 1em;\n",
    "    font-family: 'Source Code Pro', monospace;\n",
    "    font-weight: bold;\n",
    "    font-size: 1.05em;\n",
    "    color: #2c3e50;\n",
    "    background-color: #e9ecef;\n",
    "    cursor: pointer;\n",
    "}\n",
    "\n",
    ".result-header:hover {\n",
    "    background-color: #dfe4ea;\n",
    "}\n",
    "\n",
    "/* Content Styling */\n",
    ".result-content {\n",
    "    display: none;\n",
    "    padding: 0.8em 1em;\n",
    "    font-family: 'Source Code Pro', monospace;\n",
    "    font-size: 0.95em;\n",
    "    color: #34495e;\n",
    "}\n",
    "\n",
    "/* Link Styling */\n",
    ".result-link {\n",
    "    text-decoration: none;\n",
    "    color: #3498db;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<script>\n",
    "// JavaScript function to toggle visibility of the result content and icon\n",
    "function toggleContent(id, iconId) {\n",
    "    var content = document.getElementById(id);\n",
    "    var icon = document.getElementById(iconId);\n",
    "    if (content.style.display === \"none\" || content.style.display === \"\") {\n",
    "        content.style.display = \"block\";\n",
    "        icon.innerHTML = \"&#9660;\";  // Change to down-facing arrow\n",
    "    } else {\n",
    "        content.style.display = \"none\";\n",
    "        icon.innerHTML = \"&#9654;\";  // Change to right-facing arrow\n",
    "    }\n",
    "}\n",
    "</script>\n",
    "\"\"\"\n",
    "apply_custom_styles(use_base=True, custom_style=custom_style)\n",
    "setup_environment()\n",
    "\n",
    "def is_message_a_tool_call(message):\n",
    "    return hasattr(message, \"tool_calls\") and len(message.tool_calls) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1aae78-88a6-4133-b905-7e46c8e3772f",
   "metadata": {},
   "source": [
    "<div class=\"h1-container\">\n",
    "\n",
    "# 🚀 Quick Start <sub> ··· continued!</sub>\n",
    "\n",
    "In this comprehensive quick start, we will build a support chatbot in LangGraph that can:\n",
    "\n",
    "<div class=\"feature-list\">\n",
    "\n",
    "- 🧠 Answer common questions w/ a basic chatbot\n",
    "- 🔍 Answer common questions by searching the web\n",
    "- <span style=\"color: teal; font-weight: bold;\">💾 Maintain conversation state across calls [THIS NOTEBOOK]</span>\n",
    "- 🔄 Route complex queries to a human for review\n",
    "- ⚙️ Use custom state to control its behavior\n",
    "- 🌳 Rewind and explore alternative conversation paths\n",
    "\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "Previously we built a basic chatbot, and one that could operate tools... we will now enhance our ChatBot with <b>memory</b>. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c5d4a-3134-413c-81fe-dd9752fbeb66",
   "metadata": {},
   "source": [
    "<div class=\"h2-container\">\n",
    "\n",
    "## Part 3: Adding Memory to the Chatbot\n",
    "\n",
    "Our chatbot can now use tools to answer user questions, but it doesn't remember the context of previous interactions. This limits its ability to have coherent, multi-turn conversations.\n",
    "\n",
    "<div class=\"notice-block\">\n",
    "<h4 style=\"margin-top: 0; color: #ff5722;\">ENHANCING CONVERSATION CAPABILITIES!</h4>\n",
    "<p>\n",
    "    LangGraph addresses this issue through persistent checkpointing. By providing a checkpointer during graph compilation and specifying a <code>thread_id</code> when calling the graph, LangGraph automatically saves the state after each interaction. When invoked again with the same <code>thread_id</code>, the graph loads its saved state, enabling the chatbot to continue the conversation seamlessly.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59046882-161b-49be-b21a-5365156624ad",
   "metadata": {},
   "source": [
    "<div class=\"h3-container\">\n",
    "\n",
    "### 🔄 Benefits of Persistent Checkpointing\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"note-block\">\n",
    "    <p class=\"note-title\">📌 Overview</p>\n",
    "    <p>Checkpointing goes beyond simple memory by enabling advanced conversational features, such as:</p>\n",
    "    <ul>\n",
    "        <li><strong>Error Recovery:</strong> Resume from specific states in case of errors.</li>\n",
    "        <li><strong>Human-in-the-Loop Workflows:</strong> Allowing human oversight and adjustments in conversation.</li>\n",
    "        <li><strong>Time Travel Interactions:</strong> Go back to previous states for revisiting or modifying responses.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div class=\"notice-block\">\n",
    "    <span class=\"highlight\">💡 Tip:</span> Checkpointing is not limited to conversation memory; it supports more complex state management, making it ideal for scenarios where context continuity is essential.\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<b>🛠 Creating a MemorySaver Checkpointer</b>\n",
    "To enable multi-turn conversations, initialize a <code class=\"code-mention\">MemorySaver</code> checkpointer, which will handle the saving and loading of conversational states, allowing the chatbot to maintain context over multiple interactions.\n",
    "\n",
    "<div class=\"note-block\">\n",
    "    <p class=\"note-title\">📝 MemorySaver Overview</p>\n",
    "    <p><strong>MemorySaver</strong> is a base in-memory checkpoint saver that inherits from <code class=\"code-mention\">BaseCheckpointSaver</code>, <code class=\"code-mention\">AbstractContextManager</code>, and <code class=\"code-mention\">AbstractAsyncContextManager</code>.</p>\n",
    "    <p>This checkpoint saver stores checkpoints in memory using a <code class=\"code-mention\">defaultdict</code>, making it lightweight and suitable for debugging or testing. For production applications, however, it is recommended to use <strong>PostgresSaver</strong> or <strong>AsyncPostgresSaver</strong> (available in <code class=\"code-mention\">langgraph-checkpoint-postgres</code>), which provide more robust and persistent storage.</p>\n",
    "    <br>\n",
    "    <p><strong>Notable Parameters:</strong></p>\n",
    "    <ul>\n",
    "        <li><strong>serde (Optional[SerializerProtocol], default: None):</strong> The serializer used for serializing and deserializing checkpoints. This defaults to <code class=\"code-mention\">None</code> but can be customized for specific use cases.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35c8978e-c07d-4dd0-a97b-0ce3a723eea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serde': <langgraph.checkpoint.serde.jsonplus.JsonPlusSerializer at 0x106b4ed80>,\n",
       " 'storage': defaultdict(<function langgraph.checkpoint.memory.MemorySaver.__init__.<locals>.<lambda>()>,\n",
       "             {}),\n",
       " 'writes': defaultdict(dict, {})}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = MemorySaver()\n",
    "\n",
    "memory.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f503f02-d23d-42e8-9b5d-eb2681b242f4",
   "metadata": {},
   "source": [
    "<div class=\"h3-container\">\n",
    "    \n",
    "### 📉 Defining the Graph with Memory\n",
    "\n",
    "<p>In this step, we define the graph for our chatbot's memory-enhanced functionality. Previously, we constructed a custom graph using <code class=\"code-mention\">BasicToolNode</code>, but now we'll leverage LangGraph’s prebuilt <code class=\"code-mention\">ToolNode</code> and <code class=\"code-mention\">tools_condition</code>. These components streamline our workflow by adding capabilities like parallel API execution and enhanced tool coordination.</p>\n",
    "\n",
    "<div class=\"note-block\">\n",
    "    <p class=\"note-title\">🔹 Why Use Prebuilt Components?</p>\n",
    "    <p><strong>ToolNode</strong> and <strong>tools_condition</strong> offer optimized performance for tool integration, allowing us to handle multiple requests concurrently and manage complex data flows without additional configuration. This simplifies the architecture, making it more efficient for real-time applications.</p>\n",
    "</div>\n",
    "\n",
    "<p>By binding tools directly to our language model, we ensure that whenever the chatbot needs to call our search engine or other tools, it generates output in the correct JSON format automatically. This structured approach allows the chatbot to seamlessly query external APIs, retrieve responses, and deliver accurate information to users.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc5af88b-47d2-43bf-9a2c-6c07506b1732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langgraph.graph.state.StateGraph object at 0x103376060>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nodes': {'chatbot': StateNodeSpec(runnable=chatbot(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), metadata=None, input=<class '__main__.State'>, retry_policy=None),\n",
       "  'tools': StateNodeSpec(runnable=tools(tags=None, recurse=True, func_accepts_config=True, func_accepts={'writer': False, 'store': True}, tools_by_name={'tavily_search_results_json': TavilySearchResults(max_results=2, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********')))}, tool_to_state_args={'tavily_search_results_json': {}}, tool_to_store_arg={'tavily_search_results_json': None}, handle_tool_errors=True), metadata=None, input=<class '__main__.State'>, retry_policy=None)},\n",
       " 'edges': {('__start__', 'chatbot'), ('tools', 'chatbot')},\n",
       " 'branches': defaultdict(dict,\n",
       "             {'chatbot': {'tools_condition': Branch(path=tools_condition(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), ends=None, then=None)}}),\n",
       " 'support_multiple_edges': False,\n",
       " 'compiled': False,\n",
       " 'schemas': {__main__.State: {'messages': <langgraph.channels.binop.BinaryOperatorAggregate at 0x107b22580>}},\n",
       " 'channels': {'messages': <langgraph.channels.binop.BinaryOperatorAggregate at 0x107b22580>},\n",
       " 'managed': {},\n",
       " 'schema': __main__.State,\n",
       " 'input': __main__.State,\n",
       " 'output': __main__.State,\n",
       " 'config_schema': None,\n",
       " 'waiting_edges': set()}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class State(TypedDict):\n",
    "    \"\"\"Defines the state schema for the chatbot graph.\n",
    "    \n",
    "    Attributes:\n",
    "        messages (Annotated[list, add_messages]): List of conversation messages.\n",
    "            Uses add_messages reducer to append rather than overwrite messages.\n",
    "    \"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "    \n",
    "\n",
    "def initialize_graph():\n",
    "    \"\"\"Initialize the StateGraph with the defined State schema.\n",
    "    \n",
    "    Returns:\n",
    "        StateGraph: Configured graph builder instance\n",
    "    \"\"\"\n",
    "    return StateGraph(State)\n",
    "\n",
    "\n",
    "def chatbot(state: State) -> dict:\n",
    "    \"\"\"Process the current state and generate a response using the language model.\n",
    "    \n",
    "    Args:\n",
    "        state (State): Current state containing conversation messages\n",
    "        \n",
    "    Returns:\n",
    "        dict: Updated state with new message appended\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Initialize the graph builder\n",
    "graph_builder = initialize_graph()\n",
    "\n",
    "# Initialize our tool\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm = llm.bind_tools([tool,])\n",
    "\n",
    "# Add the chatbot and tool nodes to the graph\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=[tool]))\n",
    "\n",
    "# Add the conditional edge using the prebuilt `tools_condition`\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition,)\n",
    "\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "print(graph_builder)\n",
    "display(graph_builder.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aa67c2-dd1b-4bf2-8c64-eea44296d15f",
   "metadata": {},
   "source": [
    "<div class=\"h3-container\">\n",
    "\n",
    "### 🔄 Finalizing the Graph with Checkpointing\n",
    "\n",
    "<p><strong>Finally</strong>, compile the graph using the provided checkpointer.</p>\n",
    "\n",
    "<code class=\"code-mention\">graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "<p>Note that the graph’s connectivity remains unchanged from Part 2. The only addition here is the <strong>checkpointing</strong> of the state at each node, which allows the graph to save progress as it processes each step.</p>\n",
    "\n",
    "<p>This setup enables the chatbot to pick up from where it left off, enhancing conversation continuity without altering the existing structure. By storing the state in real-time, checkpointing ensures a smooth and persistent user experience across multiple interactions.</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b49509c-9d97-457c-a76a-c495fb30ccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1m\n",
      "🧜‍♀️ Mermaid Chart for Our Graph\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "cprint(\"\\n🧜‍♀️ Mermaid Chart for Our Graph\\n\", fg_color=\"blue\", bold=True)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e80e6d-28a9-4f65-a979-ab89bc221eeb",
   "metadata": {},
   "source": [
    "<div class=\"h3-container\">\n",
    "\n",
    "### 🗂 Managing Context with Configurations and Checkpoints\n",
    "\n",
    "<p>We start by choosing a thread to use as the key for this conversation.</p>\n",
    "\n",
    "<code class=\"code-mention\">config = {\"configurable\": {\"thread_id\": \"1\"}}</code>\n",
    "\n",
    "<p>Now when we call <code class=\"code-mention\">graph.stream</code> we can pass our config object and we will be able to tap into the existing conversation!</p>\n",
    "\n",
    "<p><strong>Notice</strong> the conversation memory isn't managed through an external list or storage system; instead, it's entirely handled by the checkpointer! Each conversation thread is assigned a unique configuration, allowing the chatbot to maintain context within the specified <code class=\"code-mention\">thread_id</code>. This setup enables the bot to \"remember\" past exchanges and deliver responses in context without external memory tracking.</p>\n",
    "\n",
    "<p>To inspect this in action, we could try using a different configuration to initiate a fresh conversation:</p>\n",
    "\n",
    "<code class=\"code-mention\">{\"configurable\": {\"thread_id\": \"2\"}}</code>\n",
    "\n",
    "<p>Since the <code class=\"code-mention\">thread_id</code> is different, the chatbot will treat this as a new conversation, demonstrating that checkpoints provide isolated context handling for each thread.</p>\n",
    "\n",
    "<div class=\"notice-block\">\n",
    "    <p><strong>Tip:</strong> The <code>get_state(config)</code> method allows you to inspect the graph's state for a given configuration at any point in time. A state snapshot will display all conversation details, the current config, and the next node in the process. This feature is useful for debugging and tracing your chatbot’s memory handling across threads.</p>\n",
    "</div>\n",
    "\n",
    "<p>Now let's actually run the chatbot with this configuration</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b76922-1715-4d32-930c-00f0db9c2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59593ef-5073-4279-931e-828dae971f23",
   "metadata": {},
   "source": [
    "<div class=\"h3-container\">\n",
    "\n",
    "### 🤖 Running Your Chatbot\n",
    "\n",
    "Let's run our bot...<br><b>We can now ask the bot questions outside its training data!</b><br><br>We've added some prettified features to make things look a bit better...\n",
    "\n",
    "<div class=\"feature-list\">\n",
    "\n",
    "- 🎯 Interactive chat interface with colorized output\n",
    "- 🚪 Multiple exit commands supported\n",
    "- 🛡️ Error handling and graceful fallbacks\n",
    "- 🔄 Stream-based response processing\n",
    "- 💬 Message history tracking\n",
    "\n",
    "</div>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051dc374-67cc-4371-9dd1-221e07593148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1m\n",
      "==================================================\u001b[0m\n",
      "\u001b[33m\u001b[1m🦜 Welcome to LangGraph Chat!\u001b[0m\n",
      "\u001b[37m\u001b[1mType 'quit', 'exit', 'bye', 'goodbye', or 'q' to end the conversation\u001b[0m\n",
      "\u001b[34m\u001b[1m==================================================\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User Input:  My name is Darien Schettler!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1m\n",
      "User: \u001b[0m\u001b[34mMy name is Darien Schettler!\u001b[0m\n",
      "\u001b[32m\n",
      "Assistant: \u001b[0m\u001b[32mHello, Darien Schettler! How can I assist you today?\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User Input:  I volunteer somewhere, can you find where it is?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1m\n",
      "User: \u001b[0m\u001b[34mI volunteer somewhere, can you find where it is?\u001b[0m\n",
      "\u001b[34m\u001b[1m\n",
      "🦾 LLM has decided to use the tool named 'tavily_search_results_json'\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class='result-container'>\n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\" onclick=\"toggleContent('result-content-876c2a5938e447fea3ab1c131212eb83-0', 'icon-876c2a5938e447fea3ab1c131212eb83-0')\">\n",
       "                <span>URL:</span> <a href=\"https://www.kaggle.com/dschettler8845\" target=\"_blank\" class=\"result-link\">https://www.kaggle.com/dschettler8845</a>\n",
       "                <span id=\"icon-876c2a5938e447fea3ab1c131212eb83-0\" style=\"float: right;\">&#9654;</span>  <!-- Right-facing arrow initially -->\n",
       "            </div>\n",
       "            <div id=\"result-content-876c2a5938e447fea3ab1c131212eb83-0\" class=\"result-content\">\n",
       "                <p style=\"font-family: Montserrat\"><strong>CONTENT:</strong><br><br> Darien Schettler is a Staff Machine Learning Engineer & Researcher. Darien has two degrees, one in Biological Sciences and one in Systems Engineering. Darien leverages state-of-the-art machine learning algorithms and tools to solve cutting-edge Machine Learning and Deep Learning problems. Recently Darien has shifted focus towards Multimodal Modelling and Natural Language Understanding</p>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\" onclick=\"toggleContent('result-content-876c2a5938e447fea3ab1c131212eb83-1', 'icon-876c2a5938e447fea3ab1c131212eb83-1')\">\n",
       "                <span>URL:</span> <a href=\"https://github.com/darien-schettler\" target=\"_blank\" class=\"result-link\">https://github.com/darien-schettler</a>\n",
       "                <span id=\"icon-876c2a5938e447fea3ab1c131212eb83-1\" style=\"float: right;\">&#9654;</span>  <!-- Right-facing arrow initially -->\n",
       "            </div>\n",
       "            <div id=\"result-content-876c2a5938e447fea3ab1c131212eb83-1\" class=\"result-content\">\n",
       "                <p style=\"font-family: Montserrat\"><strong>CONTENT:</strong><br><br> darien-schettler. Darien Schettler is a Staff Machine Learning Architect, Researcher and Engineer Darien has two degrees: * Biological Sciences * Systems Engineering. Prevent this user from interacting with your repositories and sending you notifications.</p>\n",
       "            </div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "Assistant: \u001b[0m\u001b[32mI couldn't find specific information about where you volunteer. If you'd like to share more details or if there's anything else you'd like to know, feel free to tell me!\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User Input:  Hint, The Knowledge Society\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1m\n",
      "User: \u001b[0m\u001b[34mHint, The Knowledge Society\u001b[0m\n",
      "\u001b[34m\u001b[1m\n",
      "🦾 LLM has decided to use the tool named 'tavily_search_results_json'\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class='result-container'>\n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\" onclick=\"toggleContent('result-content-0c1c85a71a8148a99b1764cc45b88065-0', 'icon-0c1c85a71a8148a99b1764cc45b88065-0')\">\n",
       "                <span>URL:</span> <a href=\"https://www.linkedin.com/posts/darien-schettler-bb0a5086_fantastic-update-excited-to-see-what-the-activity-7247667607384817664-rKVJ\" target=\"_blank\" class=\"result-link\">https://www.linkedin.com/posts/darien-schettler-bb0a5086_fantastic-update-excited-to-see-what-the-activity-7247667607384817664-rKVJ</a>\n",
       "                <span id=\"icon-0c1c85a71a8148a99b1764cc45b88065-0\" style=\"float: right;\">&#9654;</span>  <!-- Right-facing arrow initially -->\n",
       "            </div>\n",
       "            <div id=\"result-content-0c1c85a71a8148a99b1764cc45b88065-0\" class=\"result-content\">\n",
       "                <p style=\"font-family: Montserrat\"><strong>CONTENT:</strong><br><br> Darien Schettler's Post ... The Knowledge Society (TKS) ... Data mixture 50% general knowledge 25% maths & reasoning 17% code data and tasks 8% multilingual data 4. Preprocessing steps Uses</p>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\" onclick=\"toggleContent('result-content-0c1c85a71a8148a99b1764cc45b88065-1', 'icon-0c1c85a71a8148a99b1764cc45b88065-1')\">\n",
       "                <span>URL:</span> <a href=\"https://www.linkedin.com/posts/darien-schettler-bb0a5086_some-awesome-content-as-usual-from-leonie-activity-7246923327863169024-1Y_4\" target=\"_blank\" class=\"result-link\">https://www.linkedin.com/posts/darien-schettler-bb0a5086_some-awesome-content-as-usual-from-leonie-activity-7246923327863169024-1Y_4</a>\n",
       "                <span id=\"icon-0c1c85a71a8148a99b1764cc45b88065-1\" style=\"float: right;\">&#9654;</span>  <!-- Right-facing arrow initially -->\n",
       "            </div>\n",
       "            <div id=\"result-content-0c1c85a71a8148a99b1764cc45b88065-1\" class=\"result-content\">\n",
       "                <p style=\"font-family: Montserrat\"><strong>CONTENT:</strong><br><br> Darien Schettler's Post ... The Knowledge Society (TKS) ... Data mixture 50% general knowledge 25% maths & reasoning 17% code data and tasks 8% multilingual data 4. Preprocessing steps Uses</p>\n",
       "            </div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "Assistant: \u001b[0m\u001b[32mIt seems that you are involved with The Knowledge Society (TKS). If there's anything specific you'd like to share or discuss about your volunteering there, feel free to let me know!\u001b[0m\n",
      "\u001b[33m\u001b[1m\n",
      "Chat session interrupted. 👋 Goodbye!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def run_interactive_chat(graph: CompiledStateGraph) -> None:\n",
    "    \"\"\"Run the interactive chat interface with enhanced printing capabilities.\n",
    "\n",
    "    Args:\n",
    "        graph (CompiledStateGraph): The compiled LangGraph instance\n",
    "    \"\"\"\n",
    "    EXIT_COMMANDS = {\"quit\", \"exit\", \"q\", \"bye\", \"goodbye\"}\n",
    "    message_history = []\n",
    "    \n",
    "    # Display welcome banner\n",
    "    cprint(\"\\n\"+\"=\"*50, fg_color=\"blue\", bold=True)\n",
    "    cprint(\"🦜 Welcome to LangGraph Chat!\", fg_color=\"yellow\", bold=True)\n",
    "    cprint(\"Type 'quit', 'exit', 'bye', 'goodbye', or 'q' to end the conversation\", fg_color=\"white\", bold=True)\n",
    "    cprint(\"=\"*50+\"\\n\", fg_color=\"blue\", bold=True)\n",
    "\n",
    "    # Start interaction loop\n",
    "    while True:\n",
    "        try:\n",
    "            # Get user input with styled prompt\n",
    "            user_input = input(\"\\nUser Input: \")\n",
    "            \n",
    "            # Check for exit command\n",
    "            if user_input.lower() in EXIT_COMMANDS:\n",
    "                cprint(\"\\n👋 Goodbye! Thanks for chatting!\\n\", fg_color=\"yellow\", bold=True)\n",
    "                break\n",
    "            \n",
    "            # Process user message through graph\n",
    "            message_history.append((\"user\", user_input))\n",
    "            \n",
    "            try:\n",
    "                for event in graph.stream({\"messages\": message_history}, config, stream_mode=\"values\"):\n",
    "                    # Define what we are working with here\n",
    "                    last_message = event[\"messages\"][-1]\n",
    "                    response = last_message.content\n",
    "\n",
    "                    # Check which flavour of message it is...\n",
    "                    if is_message_a_tool_call(last_message):\n",
    "                        response_type = \"tool_calls\"\n",
    "                        cprint(f\"\\n🦾 LLM has decided to use the tool named '{last_message.tool_calls[0][\"name\"]}'\\n\", fg_color=\"blue\", bold=True)\n",
    "                    elif hasattr(last_message, \"tool_call_id\"):\n",
    "                        display_tavily_search_results(json.loads(response))\n",
    "                    else:\n",
    "                        if last_message.type==\"human\":\n",
    "                            cprint(text=response, prefix_text=\"\\nUser: \", fg_color=\"blue\", bold_prefix=True)\n",
    "                            message_history.append((\"human\", response))\n",
    "                        elif last_message.type==\"ai\":\n",
    "                            cprint(text=response, prefix_text=\"\\nAssistant: \", fg_color=\"green\", bold_prefix=True)\n",
    "                            message_history.append((\"assistant\", response))\n",
    "            except Exception as e:\n",
    "                cprint(f\"Error processing message: {str(e)}\", bg_color=\"red\", bold=True)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            cprint(\"\\nChat session interrupted. 👋 Goodbye!\", fg_color=\"yellow\", bold=True)\n",
    "            return message_history\n",
    "        except Exception as e:\n",
    "            cprint(\"\\nSomething went wrong. 👋 Goodbye!\", fg_color=\"yellow\", bold=True)\n",
    "            return message_history\n",
    "\n",
    "message_history = run_interactive_chat(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da9e85-2e5d-49c2-8cbd-572cbdb89135",
   "metadata": {},
   "source": [
    "<div class=\"h3-container\">\n",
    "  <h3 style=\"color: #2563eb; display: flex; align-items: center; gap: 0.5rem;\">\n",
    "    🎉 Congratulations!\n",
    "  </h3>\n",
    "  \n",
    "  <p>You've successfully enhanced your LangGraph chatbot with search capabilities! This implementation includes:</p>\n",
    "  \n",
    "  <div style=\"margin-left: 1rem;\">\n",
    "    <h4 style=\"color: #4b5563; margin-bottom: 0.5rem;\">1. Search Integration</h4>\n",
    "    <ul style=\"margin-top: 0;\">\n",
    "      <li>Real-time web search capabilities</li>\n",
    "      <li>Dynamic information retrieval</li>\n",
    "      <li>Broader query handling</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"notice-block\" style=\"background-color: #f3f4f6; border-left: 4px solid #2563eb; padding: 1rem; margin: 1rem 0; border-radius: 0.375rem;\">\n",
    "    <h4 style=\"margin-top: 0; color: #dc2626;\">🔍 What's Next</h4>\n",
    "    <p style=\"margin-bottom: 0;\">In the upcoming section, we'll implement:</p>\n",
    "    <ul style=\"margin-bottom: 0;\">\n",
    "      <li>Memory management for multi-turn conversations</li>\n",
    "      <li>Enhanced conversation coherence</li>\n",
    "      <li>Persistent context handling</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <p>Want to see how your chatbot processes queries? Check out the <a href=\"https://smith.langchain.com/public/4fbd7636-25af-4638-9587-5a02fdbb0172/r\" style=\"color: #2563eb; text-decoration: underline;\"><b>LangSmith trace</b></a>!</p>\n",
    "\n",
    "<div class=\"code-block\" style=\"margin-top: 1rem;\">\n",
    "<details>\n",
    "<summary style=\"cursor: pointer; color: #2563eb; font-weight: bold;\">📚 Complete Implementation</summary>\n",
    "\n",
    "<br>      \n",
    "\n",
    "```python      \n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "```\n",
    "\n",
    "</details>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe79ffb-9d49-4c48-93dc-ecd34fa3deb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
