{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd51a173-a03f-4ca8-8cf6-95ab8cfc8503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    /* Font imports */\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&family=Source+Code+Pro:ital,wght@0,200..900;1,200..900&display=swap');\n",
       "\n",
       "    /* Variables */\n",
       "    :root {\n",
       "        --primary-color: #05bfa5;\n",
       "        --primary-light: #FAFAFA;\n",
       "        --text-color: #2c3e50;\n",
       "        --code-bg: #f8f8f8;\n",
       "        --code-fg: #b22222;\n",
       "        --success-color: #479269;\n",
       "        --warning-color: #f39c12;\n",
       "        --danger-color: #e74c3c;\n",
       "        --border-radius: 8px;\n",
       "        --spacing-sm: 0.3em;\n",
       "        --spacing-md: 1em;\n",
       "        --spacing-lg: 2em;\n",
       "    }\n",
       "\n",
       "    /* Container styles */\n",
       "    .h1-container, .h2-container, .h3-container {\n",
       "        font-family: 'Montserrat', sans-serif;\n",
       "        max-width: 95%;\n",
       "        margin: var(--spacing-lg) auto;\n",
       "        line-height: 1.6;\n",
       "        color: var(--text-color);\n",
       "    }\n",
       "\n",
       "    /* List styles */\n",
       "    .feature-list {\n",
       "        background-color: var(--primary-light);\n",
       "        padding: var(--spacing-sm) var(--spacing-lg);\n",
       "        border-radius: var(--border-radius);\n",
       "        border-left: 4px solid var(--primary-color);\n",
       "        margin: var(--spacing-md) 0;\n",
       "    }\n",
       "\n",
       "    /* Code styles */\n",
       "    .code-mention {\n",
       "        font-family: 'Source Code Pro', monospace !important;\n",
       "        background-color: var(--code-bg) !important;\n",
       "        padding: 2px 5px;\n",
       "        font-weight: 600 !important;\n",
       "        border-radius: 4px;\n",
       "        color: var(--code-fg) !important;\n",
       "    }\n",
       "\n",
       "    .code-block {\n",
       "        background-color: var(--primary-light);\n",
       "        border-left: 4px solid var(--primary-color);\n",
       "        padding: var(--spacing-md);\n",
       "        margin: var(--spacing-md) 0;\n",
       "        border-radius: var(--border-radius);\n",
       "        padding: var(--spacing-lg);\n",
       "        max-width: 90%;\n",
       "    }\n",
       "\n",
       "    /* Information blocks */\n",
       "    .note-block, .notice-block {\n",
       "        padding: var(--spacing-md);\n",
       "        border-radius: var(--border-radius);\n",
       "        margin: var(--spacing-md) 0;\n",
       "    }\n",
       "\n",
       "    .note-block {\n",
       "        background-color: var(--primary-light);\n",
       "        border-left: 4px solid var(--success-color);\n",
       "    }\n",
       "\n",
       "    .notice-block {\n",
       "        background-color: var(--primary-light);\n",
       "        border-left: 4px solid var(--warning-color);\n",
       "    }\n",
       "\n",
       "    .note-title {\n",
       "        margin-top: 0;\n",
       "        color: var(--success-color);\n",
       "        font-weight: 600;\n",
       "    }\n",
       "\n",
       "    .feature-list:hover {\n",
       "        background-color: #f0f0f0;\n",
       "    }\n",
       "    .code-block:hover {\n",
       "        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
       "    }\n",
       "\n",
       "    /* Utility styles */\n",
       "    .code-comment {\n",
       "        color: #607d8b;\n",
       "        font-style: italic;\n",
       "    }\n",
       "\n",
       "    .highlight {\n",
       "        background-color: #fff176;\n",
       "        padding: 2px 5px;\n",
       "        border-radius: 3px;\n",
       "    }\n",
       "    </style>\n",
       "    <style>\n",
       "<style>\n",
       "/* General styles */\n",
       ".result-container {\n",
       "    max-width: 90%;\n",
       "    margin: 1em 0;\n",
       "}\n",
       "\n",
       "/* Card Styling */\n",
       ".result-card {\n",
       "    background-color: #f8f9fa;\n",
       "    border-left: 4px solid #05bfa5;\n",
       "    border-radius: 8px;\n",
       "    margin-bottom: 1em;\n",
       "    overflow: hidden;\n",
       "}\n",
       "\n",
       "/* Header Styling */\n",
       ".result-header {\n",
       "    display: flex;\n",
       "    justify-content: space-between;\n",
       "    align-items: center;\n",
       "    padding: 0.8em 1em;\n",
       "    font-family: 'Source Code Pro', monospace;\n",
       "    font-weight: bold;\n",
       "    font-size: 1.05em;\n",
       "    color: #2c3e50;\n",
       "    background-color: #e9ecef;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".result-header:hover {\n",
       "    background-color: #dfe4ea;\n",
       "}\n",
       "\n",
       "/* Content Styling */\n",
       ".result-content {\n",
       "    display: none;\n",
       "    padding: 0.8em 1em;\n",
       "    font-family: 'Source Code Pro', monospace;\n",
       "    font-size: 0.95em;\n",
       "    color: #34495e;\n",
       "}\n",
       "\n",
       "/* Link Styling */\n",
       ".result-link {\n",
       "    text-decoration: none;\n",
       "    color: #3498db;\n",
       "    font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "// JavaScript function to toggle visibility of the result content and icon\n",
       "function toggleContent(id, iconId) {\n",
       "    var content = document.getElementById(id);\n",
       "    var icon = document.getElementById(iconId);\n",
       "    if (content.style.display === \"none\" || content.style.display === \"\") {\n",
       "        content.style.display = \"block\";\n",
       "        icon.innerHTML = \"&#9660;\";  // Change to down-facing arrow\n",
       "    } else {\n",
       "        content.style.display = \"none\";\n",
       "        icon.innerHTML = \"&#9654;\";  // Change to right-facing arrow\n",
       "    }\n",
       "}\n",
       "</script>\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m\n",
      "‚úÖ Environment Variables Loaded Successfully\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Project library Imports\n",
    "from lc_tutorials.appearance.notebook import apply_custom_styles, cprint\n",
    "from lc_tutorials.functionality.utils import setup_environment\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import random\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import display, HTML, Markdown, Image, Javascript\n",
    "\n",
    "# Third-party imports\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from colorama import Back, Fore, Style, init\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# LangGraph Imports\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "\n",
    "# LangChain Imports\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "custom_style=\"\"\"\n",
    "<style>\n",
    "/* General styles */\n",
    ".result-container {\n",
    "    max-width: 90%;\n",
    "    margin: 1em 0;\n",
    "}\n",
    "\n",
    "/* Card Styling */\n",
    ".result-card {\n",
    "    background-color: #f8f9fa;\n",
    "    border-left: 4px solid #05bfa5;\n",
    "    border-radius: 8px;\n",
    "    margin-bottom: 1em;\n",
    "    overflow: hidden;\n",
    "}\n",
    "\n",
    "/* Header Styling */\n",
    ".result-header {\n",
    "    display: flex;\n",
    "    justify-content: space-between;\n",
    "    align-items: center;\n",
    "    padding: 0.8em 1em;\n",
    "    font-family: 'Source Code Pro', monospace;\n",
    "    font-weight: bold;\n",
    "    font-size: 1.05em;\n",
    "    color: #2c3e50;\n",
    "    background-color: #e9ecef;\n",
    "    cursor: pointer;\n",
    "}\n",
    "\n",
    ".result-header:hover {\n",
    "    background-color: #dfe4ea;\n",
    "}\n",
    "\n",
    "/* Content Styling */\n",
    ".result-content {\n",
    "    display: none;\n",
    "    padding: 0.8em 1em;\n",
    "    font-family: 'Source Code Pro', monospace;\n",
    "    font-size: 0.95em;\n",
    "    color: #34495e;\n",
    "}\n",
    "\n",
    "/* Link Styling */\n",
    ".result-link {\n",
    "    text-decoration: none;\n",
    "    color: #3498db;\n",
    "    font-weight: bold;\n",
    "}\n",
    "</style>\n",
    "\n",
    "<script>\n",
    "// JavaScript function to toggle visibility of the result content and icon\n",
    "function toggleContent(id, iconId) {\n",
    "    var content = document.getElementById(id);\n",
    "    var icon = document.getElementById(iconId);\n",
    "    if (content.style.display === \"none\" || content.style.display === \"\") {\n",
    "        content.style.display = \"block\";\n",
    "        icon.innerHTML = \"&#9660;\";  // Change to down-facing arrow\n",
    "    } else {\n",
    "        content.style.display = \"none\";\n",
    "        icon.innerHTML = \"&#9654;\";  // Change to right-facing arrow\n",
    "    }\n",
    "}\n",
    "</script>\n",
    "\"\"\"\n",
    "apply_custom_styles(use_base=True, custom_style=custom_style)\n",
    "setup_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1aae78-88a6-4133-b905-7e46c8e3772f",
   "metadata": {},
   "source": [
    "<div class=\"h1-container\">\n",
    "\n",
    "# üöÄ Quick Start <sub> ¬∑¬∑¬∑ continued!</sub>\n",
    "\n",
    "In this comprehensive quick start, we will build a support chatbot in LangGraph that can:\n",
    "\n",
    "<div class=\"feature-list\">\n",
    "\n",
    "- üß† Answer common questions w/ a basic chatbot\n",
    "- <span style=\"color: teal; font-weight: bold;\">üîç Answer common questions by searching the web [THIS NOTEBOOK]</span>\n",
    "- üíæ Maintain conversation state across calls\n",
    "- üîÑ Route complex queries to a human for review\n",
    "- ‚öôÔ∏è Use custom state to control its behavior\n",
    "- üå≥ Rewind and explore alternative conversation paths\n",
    "\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "Previously we built a basic chatbot, we will now enhance our ChatBot with <b>tools</b>. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c5d4a-3134-413c-81fe-dd9752fbeb66",
   "metadata": {},
   "source": [
    "<div class=\"h2-container\">\n",
    "\n",
    "## Part 2: Enhancing the Chatbot with Tools\n",
    "\n",
    "Since our ChatBot can't answer \"from memory\" we will integrate a <a href=\"https://python.langchain.com/docs/integrations/tools/tavily_search/\"><b>web search tool</b></a> to find relevant information and provide better responses.\n",
    "\n",
    "<div class=\"notice-block\">\n",
    "    <h4 style=\"margin-top: 0; color: #ff5722;\">PREREQUISITE REQUIREMENT!</h4>\n",
    "    <p>\n",
    "        We need to install the requirements to use the <a href=\"https://python.langchain.com/docs/integrations/tools/tavily_search/\"><b>Tavily Search Engine</b></a>, and we need to add the <b>Tavily API Key</b> to the <code class=\"code-mention\">.env</code> file in our codebase (or pass it directly).\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591ce9ba-c431-4165-b815-25c944ef7cdb",
   "metadata": {},
   "source": [
    "<div class=\"h3-container\">\n",
    "\n",
    "### üöÄ Quick Intro to Tools\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"note-block\">\n",
    "    <p class=\"note-title\">üìå Overview</p>\n",
    "    <p>In LangChain, tools are components that allow an agent or language model to perform specific actions, such as interacting with APIs or retrieving external data.</p>\n",
    "    <b>Tools are composed of the following components:</b>\n",
    "    <ul>\n",
    "        <li><strong>Name & Description:</strong> Defines the tool and clarifies its purpose for the language model.</li>\n",
    "        <li><strong>Input Schema:</strong> JSON schema that outlines the required inputs for the tool.</li>\n",
    "        <li><strong>Execution Function:</strong> The function the tool calls to perform the action.</li>\n",
    "        <li><strong>Return Options:</strong> Optionally specifies if the results should return directly to the user.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div class=\"notice-block\">\n",
    "    <span class=\"highlight\">üí° Tip:</span> Simplifying the input schema to a single string makes the tool easier for an LLM to use.\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<b>üîß Working with TavilySearchEngine</b>\n",
    "\n",
    "We will now initialize our tool to interact with the Tavily search API, enabling our ChatBot to query and retrieve results directly from the internet.\n",
    "\n",
    "The results are page summaries (and the respective URL) that our ChatBot can use to answer questions.\n",
    "\n",
    "<br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35c8978e-c07d-4dd0-a97b-0ce3a723eea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1m\n",
      "ORIGINAL RESULTS\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://cobusgreyling.medium.com/langgraph-from-langchain-explained-in-simple-terms-f7cd0c12cdbf',\n",
       "  'content': 'LangGraph. Again considering the image blow, a snippet of LangGraph Python code is shown on the left, with the graph drawn out on the right. You can see in the code where the node is defined, builder.add_node with a ReturnNodeValue.For each node having an edge defined builder.add_edge.. You also see that a is set as the entry_point and d as the finish_point.'},\n",
       " {'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'content': 'LangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. It simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing'},\n",
       " {'url': 'https://langchain-ai.github.io/langgraph/',\n",
       "  'content': 'Overview. LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1m\n",
      "ORIGINAL RESULTS\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class='result-container'>\n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\" onclick=\"toggleContent('result-content-37868f3ce7cd4d568b35265f6f16d330-0', 'icon-37868f3ce7cd4d568b35265f6f16d330-0')\">\n",
       "                <span>URL:</span> <a href=\"https://cobusgreyling.medium.com/langgraph-from-langchain-explained-in-simple-terms-f7cd0c12cdbf\" target=\"_blank\" class=\"result-link\">https://cobusgreyling.medium.com/langgraph-from-langchain-explained-in-simple-terms-f7cd0c12cdbf</a>\n",
       "                <span id=\"icon-37868f3ce7cd4d568b35265f6f16d330-0\" style=\"float: right;\">&#9654;</span>  <!-- Right-facing arrow initially -->\n",
       "            </div>\n",
       "            <div id=\"result-content-37868f3ce7cd4d568b35265f6f16d330-0\" class=\"result-content\">\n",
       "                <p style=\"font-family: Montserrat\"><strong>CONTENT:</strong><br><br> LangGraph. Again considering the image blow, a snippet of LangGraph Python code is shown on the left, with the graph drawn out on the right. You can see in the code where the node is defined, builder.add_node with a ReturnNodeValue.For each node having an edge defined builder.add_edge.. You also see that a is set as the entry_point and d as the finish_point.</p>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\" onclick=\"toggleContent('result-content-37868f3ce7cd4d568b35265f6f16d330-1', 'icon-37868f3ce7cd4d568b35265f6f16d330-1')\">\n",
       "                <span>URL:</span> <a href=\"https://www.datacamp.com/tutorial/langgraph-tutorial\" target=\"_blank\" class=\"result-link\">https://www.datacamp.com/tutorial/langgraph-tutorial</a>\n",
       "                <span id=\"icon-37868f3ce7cd4d568b35265f6f16d330-1\" style=\"float: right;\">&#9654;</span>  <!-- Right-facing arrow initially -->\n",
       "            </div>\n",
       "            <div id=\"result-content-37868f3ce7cd4d568b35265f6f16d330-1\" class=\"result-content\">\n",
       "                <p style=\"font-family: Montserrat\"><strong>CONTENT:</strong><br><br> LangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. It simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing</p>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\" onclick=\"toggleContent('result-content-37868f3ce7cd4d568b35265f6f16d330-2', 'icon-37868f3ce7cd4d568b35265f6f16d330-2')\">\n",
       "                <span>URL:</span> <a href=\"https://langchain-ai.github.io/langgraph/\" target=\"_blank\" class=\"result-link\">https://langchain-ai.github.io/langgraph/</a>\n",
       "                <span id=\"icon-37868f3ce7cd4d568b35265f6f16d330-2\" style=\"float: right;\">&#9654;</span>  <!-- Right-facing arrow initially -->\n",
       "            </div>\n",
       "            <div id=\"result-content-37868f3ce7cd4d568b35265f6f16d330-2\" class=\"result-content\">\n",
       "                <p style=\"font-family: Montserrat\"><strong>CONTENT:</strong><br><br> Overview. LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures</p>\n",
       "            </div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to format and display results as HTML\n",
    "def display_tavily_search_results(results: list[dict[str, str]]) -> None:\n",
    "    \"\"\"Displays the tavilty search results in a visually formatted HTML structure within our notebook.\n",
    "\n",
    "    This function takes a list of search results, formats each result into a styled HTML \n",
    "    \"card,\" and displays it in a Jupyter notebook. Each card includes the URL as a clickable \n",
    "    link and a content snippet. We added the CSS for this rendering in the first cell of the NB.\n",
    "\n",
    "    Args:\n",
    "        results (list[dict[str, str]]): \n",
    "            A list of dictionaries containing 'url' and 'content' keys, where:\n",
    "                - 'url' (str): The link to the search result.\n",
    "                - 'content' (str): A short snippet or description of the result.\n",
    "\n",
    "    Returns:\n",
    "        None; The function outputs HTML directly in our notebook and does not return any value.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate a unique prefix to ensure unique IDs\n",
    "    unique_prefix = str(uuid.uuid4()).replace(\"-\", \"\")\n",
    "    \n",
    "    # Begin constructing the HTML content\n",
    "    html_content = \"<div class='result-container'>\"\n",
    "    \n",
    "    # Iterate through the results\n",
    "    for idx, result in enumerate(results):\n",
    "        # Each result gets a unique ID for the collapsible functionality\n",
    "        content_id = f\"result-content-{unique_prefix}-{idx}\"\n",
    "        icon_id = f\"icon-{unique_prefix}-{idx}\"\n",
    "        html_content += f\"\"\"\n",
    "        <div class=\"result-card\">\n",
    "            <div class=\"result-header\" onclick=\"toggleContent('{content_id}', '{icon_id}')\">\n",
    "                <span>URL:</span> <a href=\"{result['url']}\" target=\"_blank\" class=\"result-link\">{result['url']}</a>\n",
    "                <span id=\"{icon_id}\" style=\"float: right;\">&#9654;</span>  <!-- Right-facing arrow initially -->\n",
    "            </div>\n",
    "            <div id=\"{content_id}\" class=\"result-content\">\n",
    "                <p style=\"font-family: Montserrat\"><strong>CONTENT:</strong><br><br> {result['content']}</p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    html_content += \"</div>\"\n",
    "    \n",
    "    # Display the final HTML with CSS and JavaScript\n",
    "    display(HTML(html_content))\n",
    "\n",
    "\n",
    "# Instantiate the TavilySearchResults tool, configuring it to return up to 2 results per query.\n",
    "tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "# Create a list of tools for potential use with agents or workflows, here containing just the TavilySearchResults tool.\n",
    "tools = [tool]\n",
    "\n",
    "# Invoke the tool with a query asking about the term \"node\" in the context of LangGraph.\n",
    "# This sends the query to the Tavily search API and retrieves information based on the configuration.\n",
    "results = tool.invoke(\"What's a 'node' in LangGraph and LangChain?\")\n",
    "\n",
    "# Display the results\n",
    "cprint(\"\\nORIGINAL RESULTS\\n\", fg_color=\"red\", bold=True)\n",
    "_ = display(results)\n",
    "\n",
    "# Display the results\n",
    "cprint(\"\\nORIGINAL RESULTS\\n\", fg_color=\"red\", bold=True)\n",
    "_ = display_tavily_search_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f503f02-d23d-42e8-9b5d-eb2681b242f4",
   "metadata": {},
   "source": [
    "<div class=\"h3-container\">\n",
    "    \n",
    "### üìà Defining the Graph with Tool Binding\n",
    "\n",
    "<p>Now, we‚Äôll start defining our graph. This setup is similar to <strong>Part 1</strong>, with the addition of the <code class=\"code-mention\">bind_tools</code> method applied directly to our LLM.\n",
    "\n",
    "<p>By binding tools to our LLM, we allow it to generate output in the correct JSON format whenever it calls our search engine tool.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc5af88b-47d2-43bf-9a2c-6c07506b1732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langgraph.graph.state.StateGraph object at 0x123370620>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nodes': {'chatbot': StateNodeSpec(runnable=chatbot(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), metadata=None, input=<class '__main__.State'>, retry_policy=None)},\n",
       " 'edges': set(),\n",
       " 'branches': defaultdict(dict, {}),\n",
       " 'support_multiple_edges': False,\n",
       " 'compiled': False,\n",
       " 'schemas': {__main__.State: {'messages': <langgraph.channels.binop.BinaryOperatorAggregate at 0x123196a00>}},\n",
       " 'channels': {'messages': <langgraph.channels.binop.BinaryOperatorAggregate at 0x123196a00>},\n",
       " 'managed': {},\n",
       " 'schema': __main__.State,\n",
       " 'input': __main__.State,\n",
       " 'output': __main__.State,\n",
       " 'config_schema': None,\n",
       " 'waiting_edges': set()}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class State(TypedDict):\n",
    "    \"\"\"Defines the state schema for the chatbot graph.\n",
    "    \n",
    "    Attributes:\n",
    "        messages (Annotated[list, add_messages]): List of conversation messages.\n",
    "            Uses add_messages reducer to append rather than overwrite messages.\n",
    "    \"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "    \n",
    "\n",
    "def initialize_graph():\n",
    "    \"\"\"Initialize the StateGraph with the defined State schema.\n",
    "    \n",
    "    Returns:\n",
    "        StateGraph: Configured graph builder instance\n",
    "    \"\"\"\n",
    "    return StateGraph(State)\n",
    "\n",
    "\n",
    "def chatbot(state: State) -> dict:\n",
    "    \"\"\"Process the current state and generate a response using the language model.\n",
    "    \n",
    "    Args:\n",
    "        state (State): Current state containing conversation messages\n",
    "        \n",
    "    Returns:\n",
    "        dict: Updated state with new message appended\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Initialize the graph builder\n",
    "graph_builder = initialize_graph()\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm = llm.bind_tools(tools)\n",
    "\n",
    "# Add the chatbot node to the graph\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "print(graph_builder)\n",
    "display(graph_builder.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e84cfc-b1b2-48e3-8550-152a408c3926",
   "metadata": {},
   "source": [
    "<div class=\"h3-container\">\n",
    "\n",
    "### üîß Implementing Tool Execution with Basic Tool Nodes\n",
    "\n",
    "<p>Next, we‚Äôll implement a function to handle tool execution when invoked. This involves <b>creating a new node</b> to add our tools to the graph. Recall that a <b>node</b> is an LLM or function that our chatbot can call.</p>\n",
    "\n",
    "<p>Below, we define a <code class=\"code-mention\">BasicToolNode</code> that inspects the latest message in the state for any <code class=\"code-mention\">tool_calls</code>. If detected, the node triggers the appropriate tools, leveraging <strong>tool_calling</strong> capabilities supported across major LLM providers, including Anthropic, OpenAI, and Google Gemini.</p>\n",
    "\n",
    "<p>Though we‚Äôll eventually use LangGraph‚Äôs prebuilt <a href=\"https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode\" target=\"_blank\" class=\"link\">ToolNode</a> for efficiency, building this node ourselves first will enhance our understanding of the process.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12f1fc14-cd91-4cd4-9f2e-1d007f8beafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langgraph.graph.state.StateGraph object at 0x123370620>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nodes': {'chatbot': StateNodeSpec(runnable=chatbot(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), metadata=None, input=<class '__main__.State'>, retry_policy=None),\n",
       "  'tools': StateNodeSpec(runnable=tools(tags=None, recurse=True, func_accepts_config=False, func_accepts={'writer': False, 'store': False}), metadata=None, input=<class '__main__.State'>, retry_policy=None)},\n",
       " 'edges': set(),\n",
       " 'branches': defaultdict(dict, {}),\n",
       " 'support_multiple_edges': False,\n",
       " 'compiled': False,\n",
       " 'schemas': {__main__.State: {'messages': <langgraph.channels.binop.BinaryOperatorAggregate at 0x123196a00>}},\n",
       " 'channels': {'messages': <langgraph.channels.binop.BinaryOperatorAggregate at 0x123196a00>},\n",
       " 'managed': {},\n",
       " 'schema': __main__.State,\n",
       " 'input': __main__.State,\n",
       " 'output': __main__.State,\n",
       " 'config_schema': None,\n",
       " 'waiting_edges': set()}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class BasicToolNode:\n",
    "    \"\"\"Executes tools based on the latest tool call from an AI message.\n",
    "\n",
    "    Attributes:\n",
    "        tools_by_name (dict): \n",
    "            Dictionary mapping tool names to their instances.\n",
    "            This enables efficient lookup and invocation of tools by name.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        \"\"\"Initializes BasicToolNode with a list of tools.\n",
    "\n",
    "        The tools are stored in a dictionary for quick access by their name.\n",
    "\n",
    "        Args:\n",
    "            tools (list): \n",
    "                List of tool instances to be used for processing tool calls.\n",
    "                Each tool should have a unique `name` attribute and an `invoke` method.\n",
    "\n",
    "        \"\"\"\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict) -> dict:\n",
    "        \"\"\"Processes the latest message and executes any requested tools.\n",
    "\n",
    "        Args:\n",
    "            inputs (dict): \n",
    "                A dictionary containing a list of messages under the \"messages\" key.\n",
    "                Expects each message to potentially include tool call data.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the tool results appended as new messages.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If no message is found in the inputs.\n",
    "        \"\"\"\n",
    "        # Retrieves the most recent message and handle errors for missing messages\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]  \n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "\n",
    "        # Initialize the outputs\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            # Invoke the tool based on its name and the arguments provided in tool_call\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            # Construct a ToolMessage with the tool's output in JSON format\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "# The functionality is packaged as a tool node\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "\n",
    "# We add this node to our graph\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "print(graph_builder)\n",
    "display(graph_builder.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b049afc4-7757-40ba-8e00-589d378e816d",
   "metadata": {},
   "source": [
    "<div class=\"h3-container\">\n",
    "\n",
    "### üîÄ Defining Conditional Edges for Dynamic Routing\n",
    "\n",
    "<p>With the tool node in place, we can now set up <code class=\"code-mention\">conditional_edges</code> to control the flow dynamically based on specific conditions.</p>\n",
    "\n",
    "<p>Recall that <strong>edges</strong> direct control flow between nodes. <strong>Conditional edges</strong> introduce logic, often using ‚Äúif‚Äù statements, to determine the next node based on the current graph <code class=\"code-mention\">state</code>. These functions take the graph state and return a string or list of strings indicating the next node(s) to invoke.</p>\n",
    "\n",
    "<p>Below, we define a router function, <code class=\"code-mention\">route_tools</code>, which examines the chatbot's output for any <code class=\"code-mention\">tool_calls</code>. We pass this function to the graph using <code class=\"code-mention\">add_conditional_edges</code>, directing the graph to check this function each time the <code class=\"code-mention\">chatbot</code> node completes to determine the next step.</p>\n",
    "\n",
    "<p>If tool calls are detected, the condition routes to <code class=\"code-mention\">tools</code>; otherwise, it routes to <code class=\"code-mention\">END</code>.</p>\n",
    "\n",
    "<p>Later, we‚Äôll streamline this with the prebuilt <b><a href=\"https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition\" target=\"_blank\" class=\"link\">tools_condition</a></b> for a more concise setup, but implementing it ourselves first clarifies the underlying process.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d662df94-66ac-4c6c-92f0-4c93620f1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_message(state: State):\n",
    "    \"\"\"Retrieve the latest message from the state.\n",
    "\n",
    "    Args:\n",
    "        state (State): Current state containing conversation messages.\n",
    "\n",
    "    Returns:\n",
    "        AIMessage: The most recent AIMessage in the state.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no messages are found in the provided state.\n",
    "    \"\"\"\n",
    "    # If the `state` is a list, assume it contains messages directly\n",
    "    # and return the last item in the list (most recent message).\n",
    "    if isinstance(state, list):\n",
    "        return state[-1]\n",
    "    \n",
    "    # If `state` is a dictionary, attempt to retrieve the list of messages\n",
    "    # using the \"messages\" key. If found, return the last message.\n",
    "    elif messages := state.get(\"messages\", []):\n",
    "        return messages[-1]\n",
    "    \n",
    "    # If neither of the above conditions are met, raise an error.\n",
    "    # This ensures that the function only proceeds when a valid list\n",
    "    # of messages is found, either as a direct list or within a dictionary.\n",
    "    else:\n",
    "        raise ValueError(\"No messages found in the provided state.\")\n",
    "\n",
    "def is_message_a_tool_call(message):\n",
    "    return hasattr(message, \"tool_calls\") and len(message.tool_calls) > 0\n",
    "\n",
    "def route_tools(state: State) -> str:\n",
    "    \"\"\"Route to ToolNode if the last message contains tool calls; otherwise, route to the end node.\n",
    "\n",
    "    This function is used within a conditional edge to determine whether the \n",
    "    conversation should proceed to a ToolNode based on the presence of tool calls \n",
    "    in the last AIMessage. If tool calls are detected, it returns 'tools' to signal \n",
    "    that the graph should invoke the ToolNode; if not, it returns 'END'.\n",
    "\n",
    "    Args:\n",
    "        state (State): Current state containing conversation messages.\n",
    "\n",
    "    Returns:\n",
    "        str: \"tools\" if tool calls are detected; otherwise, \"END\".\n",
    "    \"\"\"\n",
    "    # Retrieve the latest AI message\n",
    "    ai_message = get_latest_message(state)  \n",
    "\n",
    "    # Check if `tool_calls` attribute exists and has something in it...\n",
    "    if is_message_a_tool_call(ai_message):\n",
    "        return \"tools\"\n",
    "\n",
    "    # Otherwise we end\n",
    "    return END\n",
    "\n",
    "\n",
    "# Setting up the graph with conditional routing based on tool calls\n",
    "#   - `source` (str): The starting node. \n",
    "#        --> This conditional edge will run when exiting this node.\n",
    "#   - `path` (Union[Callable, Runnable]): \n",
    "#        --> The callable that determines the next node or nodes. \n",
    "#        --> If not specifying `path_map` it should return one or more nodes. \n",
    "#        --> If it returns END, the graph will stop execution.\n",
    "#   - `path_map` (Optional[dict[Hashable, str]]): \n",
    "#        --> Optional mapping of paths to node names. \n",
    "#        --> If omitted the paths returned by `path` should be node names.\n",
    "#   - `then` (Optional[str]): \n",
    "#        --> The name of a node to execute after the nodes selected by `path`.\n",
    "graph_builder.add_conditional_edges(\n",
    "    source=\"chatbot\",\n",
    "    path=route_tools,\n",
    "    path_map= {\n",
    "        \"tools\": \"tools\",  # Directs to \"tools\" node if route_tools returns \"tools\"\n",
    "        END: END           # Directs to the END if no tool calls are detected\n",
    "    }\n",
    ")\n",
    "\n",
    "# Adding edges to define graph flow:\n",
    "#   (1) From the \"tools\" node back to \"chatbot\" for further processing after tool execution\n",
    "#   (2) From the start node to the \"chatbot\" node to initiate the conversation\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# Compile the graph with the defined nodes, edges, and conditions\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aa67c2-dd1b-4bf2-8c64-eea44296d15f",
   "metadata": {},
   "source": [
    "<div class=\"h3-container\">\n",
    "\n",
    "### üìå Key Details on Conditional Edge Behavior\n",
    "\n",
    "<p><strong>Notice</strong> how conditional edges originate from a single node. This setup instructs the graph: whenever the <code class=\"code-mention\">chatbot</code> node completes, it should either proceed to <code class=\"code-mention\">tools</code> if a tool call is detected, or end the loop if the response is direct.</p>\n",
    "\n",
    "<p>Similar to the prebuilt <code class=\"code-mention\">tools_condition</code>, our function returns the <code class=\"code-mention\">END</code> string when no tool calls are present. Transitioning to <code class=\"code-mention\">END</code> signals that there are no remaining tasks, stopping graph execution. Since this condition covers <code class=\"code-mention\">END</code>, we don‚Äôt need to define an explicit <code class=\"code-mention\">finish_point</code>; the graph inherently knows when to finish!</p>\n",
    "\n",
    "<p>Let‚Äôs visualize the graph structure we‚Äôve created. Note that the function below has additional dependencies that aren't critical to cover in this tutorial.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b49509c-9d97-457c-a76a-c495fb30ccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1m\n",
      "üßú‚Äç‚ôÄÔ∏è Mermaid Chart for Our Graph\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cprint(\"\\nüßú‚Äç‚ôÄÔ∏è Mermaid Chart for Our Graph\\n\", fg_color=\"blue\", bold=True)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59593ef-5073-4279-931e-828dae971f23",
   "metadata": {},
   "source": [
    "<div class=\"h3-container\">\n",
    "\n",
    "### ü§ñ Running Your Chatbot\n",
    "\n",
    "Let's run our bot...<br><b>We can now ask the bot questions outside its training data!</b><br><br>We've added some prettified features to make things look a bit better...\n",
    "\n",
    "<div class=\"feature-list\">\n",
    "\n",
    "- üéØ Interactive chat interface with colorized output\n",
    "- üö™ Multiple exit commands supported\n",
    "- üõ°Ô∏è Error handling and graceful fallbacks\n",
    "- üîÑ Stream-based response processing\n",
    "- üí¨ Message history tracking\n",
    "\n",
    "</div>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "051dc374-67cc-4371-9dd1-221e07593148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1m\n",
      "==================================================\u001b[0m\n",
      "\u001b[33m\u001b[1mü¶ú Welcome to LangGraph Chat!\u001b[0m\n",
      "\u001b[37m\u001b[1mType 'quit', 'exit', 'bye', 'goodbye', or 'q' to end the conversation\u001b[0m\n",
      "\u001b[34m\u001b[1m==================================================\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User Input:  What is LangGraph and what are the criticisms it faces?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1m\n",
      "ü¶æ LLM has decided to use the tool named 'tavily_search_results_json'\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class='result-container'>\n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\" onclick=\"toggleContent('result-content-073fe437145c464f9f26e8656b69139f-0', 'icon-073fe437145c464f9f26e8656b69139f-0')\">\n",
       "                <span>URL:</span> <a href=\"https://www.langchain.com/langgraph\" target=\"_blank\" class=\"result-link\">https://www.langchain.com/langgraph</a>\n",
       "                <span id=\"icon-073fe437145c464f9f26e8656b69139f-0\" style=\"float: right;\">&#9654;</span>  <!-- Right-facing arrow initially -->\n",
       "            </div>\n",
       "            <div id=\"result-content-073fe437145c464f9f26e8656b69139f-0\" class=\"result-content\">\n",
       "                <p style=\"font-family: Montserrat\"><strong>CONTENT:</strong><br><br> LangGraph is a framework for building stateful, multi-actor agents with LLMs that can handle complex scenarios and collaborate with humans. Learn how to use LangGraph with Python or JavaScript, deploy it with LangGraph Cloud, and see examples from real-world use cases.</p>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\" onclick=\"toggleContent('result-content-073fe437145c464f9f26e8656b69139f-1', 'icon-073fe437145c464f9f26e8656b69139f-1')\">\n",
       "                <span>URL:</span> <a href=\"https://langchain-ai.github.io/langgraph/\" target=\"_blank\" class=\"result-link\">https://langchain-ai.github.io/langgraph/</a>\n",
       "                <span id=\"icon-073fe437145c464f9f26e8656b69139f-1\" style=\"float: right;\">&#9654;</span>  <!-- Right-facing arrow initially -->\n",
       "            </div>\n",
       "            <div id=\"result-content-073fe437145c464f9f26e8656b69139f-1\" class=\"result-content\">\n",
       "                <p style=\"font-family: Montserrat\"><strong>CONTENT:</strong><br><br> LangGraph is a framework for creating stateful, multi-actor applications with LLMs, using cycles, controllability, and persistence. Learn how to use LangGraph with LangChain, LangSmith, and Anthropic tools to build agent and multi-agent workflows.</p>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\" onclick=\"toggleContent('result-content-073fe437145c464f9f26e8656b69139f-2', 'icon-073fe437145c464f9f26e8656b69139f-2')\">\n",
       "                <span>URL:</span> <a href=\"https://www.datacamp.com/tutorial/langgraph-tutorial\" target=\"_blank\" class=\"result-link\">https://www.datacamp.com/tutorial/langgraph-tutorial</a>\n",
       "                <span id=\"icon-073fe437145c464f9f26e8656b69139f-2\" style=\"float: right;\">&#9654;</span>  <!-- Right-facing arrow initially -->\n",
       "            </div>\n",
       "            <div id=\"result-content-073fe437145c464f9f26e8656b69139f-2\" class=\"result-content\">\n",
       "                <p style=\"font-family: Montserrat\"><strong>CONTENT:</strong><br><br> LangGraph is a library within the LangChain ecosystem that simplifies the development of complex, multi-agent large language model (LLM) applications. Learn how to use LangGraph to create stateful, flexible, and scalable systems with nodes, edges, and state management.</p>\n",
       "            </div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1m\n",
      "ü¶æ LLM has decided to use the tool named 'tavily_search_results_json'\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class='result-container'>\n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\" onclick=\"toggleContent('result-content-2ffcbb37a7e34d9f9acea0fb1e0ba47b-0', 'icon-2ffcbb37a7e34d9f9acea0fb1e0ba47b-0')\">\n",
       "                <span>URL:</span> <a href=\"https://cobusgreyling.substack.com/p/langgraph-from-langchain-explained\" target=\"_blank\" class=\"result-link\">https://cobusgreyling.substack.com/p/langgraph-from-langchain-explained</a>\n",
       "                <span id=\"icon-2ffcbb37a7e34d9f9acea0fb1e0ba47b-0\" style=\"float: right;\">&#9654;</span>  <!-- Right-facing arrow initially -->\n",
       "            </div>\n",
       "            <div id=\"result-content-2ffcbb37a7e34d9f9acea0fb1e0ba47b-0\" class=\"result-content\">\n",
       "                <p style=\"font-family: Montserrat\"><strong>CONTENT:</strong><br><br> The challenge with agents and a constant point of criticism I have heard the most, is the high level of autonomy agents have. Makers would like to have some level of control over agents. So the introduction of agents have moved us from too much control and rigidity, to greater flexibility but a lack of control. Enter LangGraph From LangChain</p>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\" onclick=\"toggleContent('result-content-2ffcbb37a7e34d9f9acea0fb1e0ba47b-1', 'icon-2ffcbb37a7e34d9f9acea0fb1e0ba47b-1')\">\n",
       "                <span>URL:</span> <a href=\"https://towardsdatascience.com/langgraph-intuitively-and-exhaustively-explained-435ef706f0f9\" target=\"_blank\" class=\"result-link\">https://towardsdatascience.com/langgraph-intuitively-and-exhaustively-explained-435ef706f0f9</a>\n",
       "                <span id=\"icon-2ffcbb37a7e34d9f9acea0fb1e0ba47b-1\" style=\"float: right;\">&#9654;</span>  <!-- Right-facing arrow initially -->\n",
       "            </div>\n",
       "            <div id=\"result-content-2ffcbb37a7e34d9f9acea0fb1e0ba47b-1\" class=\"result-content\">\n",
       "                <p style=\"font-family: Montserrat\"><strong>CONTENT:</strong><br><br> LangGraph ‚Äî Intuitively and Exhaustively Explained | by Daniel Warfield | Sep, 2024 | Towards Data Science LangGraph ‚Äî Intuitively and Exhaustively Explained In this article we‚Äôll explore ‚ÄúLangGraph‚Äù, a cutting-edge tool for making LLM agents that are actually useful. We‚Äôll then discuss how LangGraph can be used to address these shortcomings to make more useful and maintainable agents. We‚Äôll use this state graph to build an agent which is capable of performing a complex task which requires the agent to deal with natural conversation, hard rules, and application logic. By the end of this article you‚Äôll understand why LangGraph exists, why it‚Äôs important, and how to use it within your own projects.</p>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"result-card\">\n",
       "            <div class=\"result-header\" onclick=\"toggleContent('result-content-2ffcbb37a7e34d9f9acea0fb1e0ba47b-2', 'icon-2ffcbb37a7e34d9f9acea0fb1e0ba47b-2')\">\n",
       "                <span>URL:</span> <a href=\"https://towardsdatascience.com/ai-agent-workflows-a-complete-guide-on-whether-to-build-with-langgraph-or-langchain-117025509fa0\" target=\"_blank\" class=\"result-link\">https://towardsdatascience.com/ai-agent-workflows-a-complete-guide-on-whether-to-build-with-langgraph-or-langchain-117025509fa0</a>\n",
       "                <span id=\"icon-2ffcbb37a7e34d9f9acea0fb1e0ba47b-2\" style=\"float: right;\">&#9654;</span>  <!-- Right-facing arrow initially -->\n",
       "            </div>\n",
       "            <div id=\"result-content-2ffcbb37a7e34d9f9acea0fb1e0ba47b-2\" class=\"result-content\">\n",
       "                <p style=\"font-family: Montserrat\"><strong>CONTENT:</strong><br><br> AI Agent Workflows: A Complete Guide on Whether to Build With LangGraph or LangChain | by Sandi Besen | Oct, 2024 | Towards Data Science While LangGraph focuses on creating a more flexible, granular, process based workflow that can include AI agents, tool calls, procedural code, and more. If there is no agent in the graph, then much like in LanchChain‚Äôs chain, the tool can be included in the workflow based on conditional logic. In LangChain, the error handling is explicitly defined by the developer and can either be done by introducing retry logic into the chain its self or in the agent if a tool call fails.</p>\n",
       "            </div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m\n",
      "Assistant: \u001b[0m\u001b[32mLangGraph is a framework designed for building stateful, multi-actor applications with large language models (LLMs). It aims to manage complex scenarios and facilitate collaboration between AI agents and humans. LangGraph is part of the LangChain ecosystem and enhances the development of multi-agent workflows by integrating tools such as LangChain, LangSmith, and Anthropic. It focuses on creating flexible, scalable systems through the use of nodes, edges, and state management, and can be deployed with LangGraph Cloud for real-world applications.\n",
      "\n",
      "### Criticisms of LangGraph\n",
      "1. **Autonomy vs. Control**: A major criticism of LangGraph, and similar agent frameworks, is the high level of autonomy given to agents. While this allows for greater flexibility, it also results in a lack of control for the developers or users. Many users desire a balance where they can maintain some level of control over the agents.\n",
      "   \n",
      "2. **Complexity in Workflow**: While LangGraph provides a more granular, process-based workflow, it can introduce complexity in managing AI agents, tool calls, and procedural code. This complexity can make it challenging to implement error handling and other controls effectively.\n",
      "\n",
      "These criticisms highlight the ongoing balance between flexibility and control in AI agent frameworks, as developers strive to create systems that are both powerful and manageable.\u001b[0m\n",
      "\u001b[33m\u001b[1m\n",
      "Chat session interrupted. üëã Goodbye!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def run_interactive_chat(graph: CompiledStateGraph) -> None:\n",
    "    \"\"\"Run the interactive chat interface with enhanced printing capabilities.\n",
    "\n",
    "    Args:\n",
    "        graph (CompiledStateGraph): The compiled LangGraph instance\n",
    "    \"\"\"\n",
    "    EXIT_COMMANDS = {\"quit\", \"exit\", \"q\", \"bye\", \"goodbye\"}\n",
    "    message_history = []\n",
    "    \n",
    "    # Display welcome banner\n",
    "    cprint(\"\\n\"+\"=\"*50, fg_color=\"blue\", bold=True)\n",
    "    cprint(\"ü¶ú Welcome to LangGraph Chat!\", fg_color=\"yellow\", bold=True)\n",
    "    cprint(\"Type 'quit', 'exit', 'bye', 'goodbye', or 'q' to end the conversation\", fg_color=\"white\", bold=True)\n",
    "    cprint(\"=\"*50+\"\\n\", fg_color=\"blue\", bold=True)\n",
    "\n",
    "    # Start interaction loop\n",
    "    while True:\n",
    "        try:\n",
    "            # Get user input with styled prompt\n",
    "            user_input = input(\"\\nUser Input: \")\n",
    "            \n",
    "            # Check for exit command\n",
    "            if user_input.lower() in EXIT_COMMANDS:\n",
    "                cprint(\"\\nüëã Goodbye! Thanks for chatting!\\n\", fg_color=\"yellow\", bold=True)\n",
    "                break\n",
    "            \n",
    "            # Process user message through graph\n",
    "            message_history.append((\"user\", user_input))\n",
    "            \n",
    "            try:\n",
    "                for event in graph.stream({\"messages\": message_history}):\n",
    "                    for value in event.values():\n",
    "\n",
    "                        # Define what we are working with here\n",
    "                        last_message = value[\"messages\"][-1]\n",
    "                        response = last_message.content\n",
    "\n",
    "                        # Check which flavour of message it is...\n",
    "                        if is_message_a_tool_call(last_message):\n",
    "                            response_type = \"tool_calls\"\n",
    "                            cprint(f\"\\nü¶æ LLM has decided to use the tool named '{last_message.tool_calls[0][\"name\"]}'\\n\", fg_color=\"blue\", bold=True)\n",
    "                        elif hasattr(last_message, \"tool_call_id\"):\n",
    "                            display_tavily_search_results(json.loads(response))\n",
    "                        else:\n",
    "                            cprint(text=response, prefix_text=\"\\nAssistant: \", fg_color=\"green\", bold_prefix=True)\n",
    "                        message_history.append((\"assistant\", response))\n",
    "            except Exception as e:\n",
    "                cprint(f\"Error processing message: {str(e)}\", bg_color=\"red\", bold=True)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            cprint(\"\\nChat session interrupted. üëã Goodbye!\", fg_color=\"yellow\", bold=True)\n",
    "            return message_history\n",
    "        except Exception as e:\n",
    "            cprint(\"\\nSomething went wrong. üëã Goodbye!\", fg_color=\"yellow\", bold=True)\n",
    "            return message_history\n",
    "\n",
    "message_history = run_interactive_chat(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da9e85-2e5d-49c2-8cbd-572cbdb89135",
   "metadata": {},
   "source": [
    "<div class=\"h3-container\">\n",
    "  <h3 style=\"color: #2563eb; display: flex; align-items: center; gap: 0.5rem;\">\n",
    "    üéâ Congratulations!\n",
    "  </h3>\n",
    "  \n",
    "  <p>You've successfully enhanced your LangGraph chatbot with search capabilities! This implementation includes:</p>\n",
    "  \n",
    "  <div style=\"margin-left: 1rem;\">\n",
    "    <h4 style=\"color: #4b5563; margin-bottom: 0.5rem;\">1. Search Integration</h4>\n",
    "    <ul style=\"margin-top: 0;\">\n",
    "      <li>Real-time web search capabilities</li>\n",
    "      <li>Dynamic information retrieval</li>\n",
    "      <li>Broader query handling</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"notice-block\" style=\"background-color: #f3f4f6; border-left: 4px solid #2563eb; padding: 1rem; margin: 1rem 0; border-radius: 0.375rem;\">\n",
    "    <h4 style=\"margin-top: 0; color: #dc2626;\">üîç What's Next</h4>\n",
    "    <p style=\"margin-bottom: 0;\">In the upcoming section, we'll implement:</p>\n",
    "    <ul style=\"margin-bottom: 0;\">\n",
    "      <li>Memory management for multi-turn conversations</li>\n",
    "      <li>Enhanced conversation coherence</li>\n",
    "      <li>Persistent context handling</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <p>Want to see how your chatbot processes queries? Check out the <a href=\"https://smith.langchain.com/public/4fbd7636-25af-4638-9587-5a02fdbb0172/r\" style=\"color: #2563eb; text-decoration: underline;\"><b>LangSmith trace</b></a>!</p>\n",
    "\n",
    "<div class=\"code-block\" style=\"margin-top: 1rem;\">\n",
    "<details>\n",
    "<summary style=\"cursor: pointer; color: #2563eb; font-weight: bold;\">üìö Complete Implementation</summary>\n",
    "\n",
    "<br>      \n",
    "\n",
    "```python      \n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# Any time a tool is called, we return to the chatbot\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph = graph_builder.compile()</code></pre>\n",
    "```\n",
    "\n",
    "</details>\n",
    "</div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
